{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spectral\n",
    "! pip install plotly\n",
    "! pip install pathlib\n",
    "! pip install spectral\n",
    "! pip install numpy\n",
    "! pip install opencv-python\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import *\n",
    "from  pathlib import Path\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "data_dir = r'E:\\PHD\\Blueberry\\Blueberry\\Blueberry_Pretest'\n",
    "\n",
    "names = [ 'Blueberry_Pretest_Sample000_05112022', 'Blueberry_Pretest_Dark_05112022', 'Blueberry_Pretest_White_05112022']\n",
    "path = Path(data_dir) / f'{names[0]}.bil'.__str__()\n",
    "path_head = Path(data_dir) / f'{names[0]}.bil.hdr'.__str__()\n",
    "\n",
    "ref_path = Path(data_dir) / f'{names[1]}.bil'.__str__()\n",
    "ref_path_head = Path(data_dir) / f'{names[1]}.bil.hdr'.__str__()\n",
    "\n",
    "ref1_path = Path(data_dir) / f'{names[2]}.bil'.__str__()\n",
    "ref1_path_head = Path(data_dir) / f'{names[2]}.bil.hdr'.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral.io import envi\n",
    "\"\"\"\n",
    "    Returns:\n",
    "\n",
    "        :class:`spectral.SpyFile` or :class:`spectral.io.envi.SpectralLibrary`\n",
    "        object.\n",
    "\"\"\"\n",
    "data = envi.open(path_head, path)\n",
    "ref_data = envi.open(ref_path_head, ref_path)\n",
    "ref1_data = envi.open(ref1_path_head, ref1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\tData Source:   'E:\\PHD\\Blueberry\\Blueberry\\Blueberry_Pretest_Sample000_05112022.bil'\n",
       "\t# Rows:           1000\n",
       "\t# Samples:        1600\n",
       "\t# Bands:           462\n",
       "\tInterleave:        BIL\n",
       "\tQuantization:  16 bits\n",
       "\tData format:    uint16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data#, ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "im = data[:, :, 100]\n",
    "im_np = np.array(im/im.max()*255, dtype=np.uint8).squeeze()\n",
    "print(im_np.shape)\n",
    "fig = px.imshow(im_np)\n",
    "fig.show()\n",
    "data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "taget_y_0 = 119\n",
    "taget_y_1 = 290\n",
    "taget_x_0 = 162\n",
    "taget_x_1 = 350\n",
    "\n",
    "im = im_np[taget_y_0:taget_y_1, taget_x_0:taget_x_1]\n",
    "fig = px.imshow(im)\n",
    "fig.show()\n",
    "data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "ref_data\n",
    "band_num = data.shape[2]\n",
    "im_mins = [ ]\n",
    "im_maxs= [ ]\n",
    "ref_mins= [ ]\n",
    "ref_maxs= [ ]\n",
    "for idx in range(band_num):\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    im_mins.append(im.min())\n",
    "    im_maxs.append(im.max())\n",
    "\n",
    "    ref_mins.append(ref.min())\n",
    "    ref_maxs.append(ref.max())\n",
    "im_mins = np.array(im_mins)\n",
    "im_maxs = np.array(im_maxs)\n",
    "ref_mins = np.array(ref_mins)\n",
    "ref_maxs = np.array(ref_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "ref_data\n",
    "band_num = data.shape[2]\n",
    "ref1_mins= [ ]\n",
    "ref1_maxs= [ ]\n",
    "for idx in range(band_num):\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    ref1_mins.append(ref1.min())\n",
    "    ref1_maxs.append(ref1.max())\n",
    "ref1_mins = np.array(ref1_mins)\n",
    "ref1_maxs = np.array(ref1_maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "data_num = im_maxs.shape[0]\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths = [float(x) for x in wavelengths]\n",
    "x_data = np.array(wavelengths)\n",
    "\n",
    "#x_data = np.arange(0, data_num)\n",
    "\n",
    "#df = pd.DataFrame(dict(\n",
    "#    x = x_data.tolist(),\n",
    "#    im_mins = im_mins.tolist(),\n",
    "#    im_maxs = im_maxs.tolist(),\n",
    "#    ref_mins = ref_mins.tolist(),\n",
    "#    ref_maxs = ref_maxs.tolist(),\n",
    "#))\n",
    "\n",
    "type = ['im_mins']*data_num+['im_maxs']*data_num+['ref_mins']*data_num+['ref_maxs']*data_num+['ref1_mins']*data_num+['ref1_maxs']*data_num\n",
    "x = x_data.tolist()*6\n",
    "\n",
    "df = pd.DataFrame(dict(\n",
    "    band = x,\n",
    "    responce= im_mins.tolist() + im_maxs.tolist() + ref_mins.tolist() + ref_maxs.tolist() + ref1_mins.tolist() + ref1_maxs.tolist(),\n",
    "    type= type,\n",
    "))\n",
    "fig = px.line(df, x=\"band\", y=\"responce\", color='type') \n",
    "fig.show()\n",
    "\n",
    "#df = df.sort_values(by=\"x\")\n",
    "#fig = px.line(df, x=\"x\", y=\"y\", title=\"Sorted Input\") \n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (a) wavelength-wise correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wavelengths: 637.26"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "def on_trackbar(idx):\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    #print(f'im min: {im.min()}, max: {im.max()}')\n",
    "    #print(f'ref min: {ref.min()}, max: {ref.max()}')\n",
    "    im_corrected = im/(ref1-ref)\n",
    "    im_corrected /= im_corrected.max()\n",
    "    print(\"\\r\", f'wavelengths: {wavelengths[idx]}', end=\"\", flush=True)\n",
    "    #print(f'corrected min: {im_corrected.min()}, max: {im_corrected.max()}')\n",
    "    # seems range within 0-1.0 float, so directly show\n",
    "    cv.imshow(title_window, im_corrected)\n",
    "title_window = 'HSI corrected'\n",
    "cv.namedWindow(title_window, 0)\n",
    "slider_max = data.shape[2]\n",
    "trackbar_name = f'{wavelengths_bar[0]}:{wavelengths_bar[-1]}'\n",
    "cv.createTrackbar(trackbar_name, title_window , 0, slider_max, on_trackbar)\n",
    "on_trackbar(0)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wavelengths: 393.8"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "def on_trackbar(idx):\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    #print(f'im min: {im.min()}, max: {im.max()}')\n",
    "    #print(f'ref min: {ref.min()}, max: {ref.max()}')\n",
    "    im_corrected = im/(ref1-ref)\n",
    "    im_corrected /= im_corrected.max()\n",
    "    print(\"\\r\", f'wavelengths: {wavelengths[idx]}', end=\"\", flush=True)\n",
    "    #print(f'corrected min: {im_corrected.min()}, max: {im_corrected.max()}')\n",
    "    # seems range within 0-1.0 float, so directly show\n",
    "\n",
    "    taget_y_0 = 119\n",
    "    taget_y_1 = 290\n",
    "    taget_x_0 = 162\n",
    "    taget_x_1 = 350\n",
    "    im_corrected = im_corrected[taget_y_0:taget_y_1, taget_x_0:taget_x_1]\n",
    "    cv.imshow(title_window, im_corrected)\n",
    "\n",
    "title_window = 'HSI corrected'\n",
    "cv.namedWindow(title_window, 0)\n",
    "slider_max = data.shape[2]\n",
    "trackbar_name = f'{wavelengths_bar[0]}:{wavelengths_bar[-1]}'\n",
    "cv.createTrackbar(trackbar_name, title_window , 0, slider_max, on_trackbar)\n",
    "on_trackbar(0)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) RGB color image\n",
    "Red (640 nm), Green (550 nm) and Blue (460 nm) channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'891.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelengths[373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([891.1, 880.28, 910.06], [373, 365, 387])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tarrget_wavelengths = [640, 550, 460]\n",
    "tarrget_wavelengths = [891, 880, 910]\n",
    "\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths = [float(x) for x in wavelengths]\n",
    "\n",
    "import numpy as np\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx], idx\n",
    "\n",
    "tarrget_values = []\n",
    "tarrget_idxes = []\n",
    "for target in tarrget_wavelengths:\n",
    "    nearest_value, nearest_idx= find_nearest(wavelengths, target)\n",
    "    tarrget_values.append(nearest_value)\n",
    "    tarrget_idxes.append(nearest_idx)\n",
    "tarrget_values, tarrget_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "data_num =  data.shape[2]\n",
    "im_corrected_rgb = None\n",
    "im_corrected_bgr = None\n",
    "def on_trackbar(idx):\n",
    "    im_channels =  []\n",
    "    for idx_target in tarrget_idxes:\n",
    "        #new_idx = idx+idx_target\n",
    "        new_idx = idx+idx_target-50\n",
    "        # need convert to int to avoid issues\n",
    "        new_idx = int(new_idx)\n",
    "        if new_idx >= data_num or new_idx < 0:\n",
    "            print('new_idx is exceed, set to boundary value')\n",
    "            new_idx = min(max(0, new_idx), data_num-1)\n",
    "        im = data[: , :, new_idx]\n",
    "        ref = ref_data[: , :, new_idx]\n",
    "        ref1 = ref1_data[: , :, new_idx]\n",
    "        im_corrected = im/(ref1-ref)\n",
    "        im_corrected /= im_corrected.max()\n",
    "        im_channels.append(im_corrected)\n",
    "    im_corrected_rgb = np.concatenate(im_channels, axis=2)\n",
    "    # cv.imshow use bgr for show\n",
    "    im_corrected_bgr = im_corrected_rgb[:, :, ::-1]\n",
    "    cv.imshow(title_window, im_corrected_bgr)\n",
    "title_window = 'HSI corrected'\n",
    "cv.namedWindow(title_window, 0)\n",
    "#slider_max = data_num\n",
    "slider_max = 100\n",
    "trackbar_name = 'band %d' % slider_max\n",
    "#cv.createTrackbar(trackbar_name, title_window , 0, slider_max, on_trackbar)\n",
    "cv.createTrackbar(trackbar_name, title_window , 50, slider_max, on_trackbar)\n",
    "#on_trackbar(0)\n",
    "on_trackbar(50)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) & (d) Segment samples / Extract boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "im_channels =  []\n",
    "for idx_target in tarrget_idxes:\n",
    "    new_idx = idx+idx_target\n",
    "    new_idx = int(new_idx)\n",
    "    im = data[: , :, new_idx]\n",
    "    ref = ref_data[: , :, new_idx]\n",
    "    ref1 = ref1_data[: , :, new_idx]\n",
    "    im_corrected = im/(ref1- ref)\n",
    "    im_channels.append(im_corrected)\n",
    "im_corrected_rgb = np.concatenate(im_channels, axis=2)\n",
    "# cv.imshow use bgr for show\n",
    "im_corrected_bgr = im_corrected_rgb[:, :, ::-1]\n",
    "cv.imshow(title_window, im_corrected_bgr)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.3851091142490373, (1000, 1600, 3))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_corrected_rgb.min(), im_corrected_rgb.max(), im_corrected_rgb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "im_corrected_rgb_norm = (im_corrected_rgb - im_corrected_rgb.min()) / (im_corrected_rgb.max() - im_corrected_rgb.min())\n",
    "im_corrected_rgb_norm_rescale = np.array(im_corrected_rgb_norm*255, dtype=np.uint8).squeeze()\n",
    "print(im_corrected_rgb_norm_rescale.shape)\n",
    "fig = px.imshow(im_corrected_rgb_norm_rescale)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graph Cut\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = im_corrected_rgb_norm_rescale\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "rect = (400,0,1250,1000)\n",
    "cv.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv.GC_INIT_WITH_RECT)\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "#plt.imshow(img),plt.colorbar(),plt.show()\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "im_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, im_t = cv.threshold(im_gray, 1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "fig = px.imshow(im_t)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this cell shows distribution, but need 8s to run\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "im_corrected_rgb_data = im_corrected_rgb_norm_rescale.reshape(-1, 3)\n",
    "data_num = im_corrected_rgb_data.shape[0]\n",
    "x_data = np.arange(0, data_num)\n",
    "\n",
    "\n",
    "type = ['R']*data_num+['G']*data_num+['B']*data_num\n",
    "df = pd.DataFrame(dict(\n",
    "    #band = x,\n",
    "    intensity= im_corrected_rgb_data[:, 0].tolist() + im_corrected_rgb_data[:, 1].tolist() + im_corrected_rgb_data[:, 2].tolist(),\n",
    "    type= type,\n",
    "))\n",
    "fig = px.histogram(df, x=\"intensity\", color='type', color_discrete_sequence=['red', 'green', 'blue']) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "im = im_corrected_rgb_norm_rescale\n",
    "im_gray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "#im = cv.Sobel(im, cv.CV_64F, 1, 1, ksize=3)\n",
    "\n",
    "ret, im_t = cv.threshold(im_gray, 20, 255, cv.THRESH_BINARY)\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_t)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for convinenent use larger filter\n",
    "#kernel=cv.getStructuringElement(cv.MORPH_RECT,(20,20))\n",
    "kernel=cv.getStructuringElement(cv.MORPH_RECT,(5,5))\n",
    "eroded=cv.erode(im_t,kernel)\n",
    "kernel=cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
    "#iterations = 10\n",
    "iterations = 2\n",
    "im_t_dilated=cv.dilate(eroded,kernel, iterations=iterations)\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_t_dilated)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im_corrected_rgb_norm_rescale[:,:,::-1]\n",
    "im_copy = im.copy()\n",
    "contours, hierarchy = cv.findContours(image=im_t_dilated, mode=cv.RETR_EXTERNAL,\n",
    "                                    method=cv.CHAIN_APPROX_SIMPLE)\n",
    "cv.drawContours(image=im_copy, contours=contours, contourIdx=-1,\n",
    "                color=(0, 255, 0), thickness=2, lineType=cv.LINE_AA)\n",
    "# see the results\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_copy)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im_corrected_rgb_norm_rescale[:,:,::-1]\n",
    "im_copy = im.copy()\n",
    "for contour in contours:\n",
    "    color = np.random.randint(0, 256, 3).tolist()\n",
    "    cv.drawContours(image=im_copy, contours=[contour], contourIdx=-1,\n",
    "                    color=color, thickness=2, lineType=cv.LINE_AA)\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_copy)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (e) Number the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im_t_dilated\n",
    "im_copy = im.copy()\n",
    "font=cv.FONT_HERSHEY_DUPLEX\n",
    "center_pts = []\n",
    "center_refs = []\n",
    "for i_contour, contour in enumerate(contours):\n",
    "    x = int(contour[:, :, 0].mean())\n",
    "    y = int(contour[:, :, 1].mean())\n",
    "    center_refs.append(x+4*y)\n",
    "    center_pts.append((x, y))\n",
    "idx_sorted = np.argsort(center_refs)\n",
    "for i_idx_sorted, idx in enumerate(idx_sorted):\n",
    "    x, y = center_pts[idx]\n",
    "    cv.putText(im_copy, str(i_idx_sorted+1) , (x-5,y+5), font, 1, 0, 2)\n",
    "print(len(contours))\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_copy)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wavelengths: 916.83"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "def on_trackbar(idx):\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    im_corrected = im/(ref1-ref)\n",
    "    im_corrected/=im_corrected.max()\n",
    "\n",
    "    print(\"\\r\", f'wavelengths: {wavelengths[idx]}', end=\"\", flush=True)\n",
    "    cv.putText(im_corrected, str(wavelengths[idx]) , (50, 50), font, 1, 255, 2)\n",
    "    for i_idx_sorted, idx in enumerate(idx_sorted):\n",
    "        x, y = center_pts[idx]\n",
    "        cv.putText(im_corrected, str(i_idx_sorted+1) , (x-100,y-70), font, 1, 255, 2)\n",
    "    cv.imshow(title_window, im_corrected)\n",
    "title_window = 'HSI corrected'\n",
    "cv.namedWindow(title_window, 0)\n",
    "slider_max = data.shape[2]\n",
    "trackbar_name = f'{wavelengths_bar[0]}:{wavelengths_bar[-1]}'\n",
    "cv.createTrackbar(trackbar_name, title_window , 0, slider_max, on_trackbar)\n",
    "on_trackbar(0)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (f) Calculate the pixel areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im_t_dilated\n",
    "im_copy = im.copy()\n",
    "font=cv.FONT_HERSHEY_DUPLEX\n",
    "center_pts = []\n",
    "center_areas = []\n",
    "for i_contour, contour in enumerate(contours):\n",
    "    x = int(contour[:, :, 0].mean())\n",
    "    y = int(contour[:, :, 1].mean())\n",
    "    area = cv.contourArea(contour)\n",
    "    area = round(area, 2)\n",
    "    center_pts.append((x, y))\n",
    "    center_areas.append(area)\n",
    "for i_idx_sorted, idx in enumerate(idx_sorted):\n",
    "    x, y = center_pts[idx]\n",
    "    area = center_areas[idx]\n",
    "    cv.putText(im_copy, str(area) , (x-50,y+5), font, 0.8, 0, 2)\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.imshow(title_window, im_copy)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7340.5, 15432.361111111111, 20488.5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_areas = np.array(center_areas)\n",
    "center_areas.min(), center_areas.mean(), center_areas.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15432.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3458.726767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7340.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14707.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16227.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17530.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20488.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count     18.000000\n",
       "mean   15432.361111\n",
       "std     3458.726767\n",
       "min     7340.500000\n",
       "25%    14707.500000\n",
       "50%    16227.250000\n",
       "75%    17530.875000\n",
       "max    20488.500000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_areas = np.array(center_areas)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_describe = pd.DataFrame(center_areas)\n",
    "df_describe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (g) each sample spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 462/462 [01:25<00:00,  5.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([14, 12, 15, 13, 16, 17, 10, 9, 8, 7, 6, 11, 3, 0, 1, 2, 5, 4])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "need 5 minutes to run\n",
    "\"\"\"\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths = [float(x) for x in wavelengths]\n",
    "data_num = len(wavelengths)\n",
    "peanuts_dict = {}\n",
    "for idx in tqdm(range(data_num), ncols=80):\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    im_corrected = im/(ref1- ref)\n",
    "    for i_idx_sorted, idx in enumerate(idx_sorted):\n",
    "        contour = contours[idx]\n",
    "        mask = np.zeros_like(im_corrected)\n",
    "        cv.drawContours(mask, [contour], -1, 255,-1)\n",
    "        pts  = np.where(mask == 255)\n",
    "        roi = im_corrected[pts[0], pts[1]]\n",
    "        mean_spectral = round(np.mean(roi), 4)\n",
    "        #print('mean_spectral:', mean_spectral)\n",
    "        if i_idx_sorted not in peanuts_dict:\n",
    "            peanuts_dict[i_idx_sorted] = []\n",
    "        peanuts_dict[i_idx_sorted].append(mean_spectral)\n",
    "peanuts_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peanuts_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "data_num = len(wavelengths)\n",
    "x_data = np.array(wavelengths)\n",
    "\n",
    "\n",
    "item_num = len(peanuts_dict.keys())\n",
    "\n",
    "peanuts_dict_sorted=sorted(peanuts_dict.items(), key=lambda item :item[0])\n",
    "\n",
    "type = []\n",
    "responce = []\n",
    "for idx, values in peanuts_dict_sorted:\n",
    "    type += [str(idx+1)]*data_num\n",
    "    responce += values\n",
    "\n",
    "x = x_data.tolist()*item_num\n",
    "df = pd.DataFrame(dict(\n",
    "    wavelength = x,\n",
    "    reflectance= responce,\n",
    "    number = type,\n",
    "))\n",
    "fig = px.line(df, x=\"wavelength\", y=\"reflectance\", color='number',\n",
    "                 labels={\n",
    "                     \"wavelength\": \"Wavelength (nm)\",\n",
    "                     \"reflectance\": \"Reflectance (a.u.)\",\n",
    "                 }\n",
    ") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# felzenszwalb-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install felzenszwalb-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "need 1min for 800x1400\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "#%matplotlib inline\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from felzenszwalb_segmentation_revised import segment\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#import plotly.express as px\n",
    "#from plotly.subplots import make_subplots\n",
    "#from plotly.graph_objs import Image as plot_Image\n",
    "\n",
    "image_files = glob(r'E:\\PHD\\Blueberry\\Blueberry\\samples\\*.jpg')\n",
    "im_num = len(image_files)\n",
    "#fig = make_subplots(rows=1, cols=2)\n",
    "#tot_ims= [ ]\n",
    "\n",
    "norm = plt.Normalize(1,4)\n",
    "cmap = plt.cm.RdYlGn\n",
    "np.random.seed(0)\n",
    "c = np.random.randint(1,5,size=15)\n",
    "\n",
    "for i_im in range(im_num):\n",
    "    if i_im !=2:\n",
    "        continue\n",
    "    random.seed(10)\n",
    "    image = np.array(Image.open(image_files[i_im]))\n",
    "    segmented_image = segment(image, 0.2, 400, 50)\n",
    "    segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "    #tot_ims.append(image)\n",
    "    #tot_ims.append(segmented_image)\n",
    "    #tot_im = np.concatenate([image, segmented_image], 1)\n",
    "    #tot_im1 = np.concatenate([segmented_image, image], 1)\n",
    "    #tot_im = np.concatenate([tot_im, tot_im1], 0)\n",
    "    #fig = px.imshow(tot_im)\n",
    "    #fig.update_xaxes(showticklabels = False)\n",
    "    #fig.update_yaxes(showticklabels = False)\n",
    "    #fig.update_traces(hoverinfo='none', hovertemplate=None)\n",
    "    #fig.add_trace(px.imshow(image).data[0], row=i_im, col=1)\n",
    "    #fig.add_trace(px.imshow(segmented_image).data[0], row=i_im, col=2)\n",
    "\n",
    "    #fig1 = px.imshow(image)\n",
    "    #fig2 = px.imshow(segmented_image)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    handle1 = plt.imshow(image)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    handle2= plt.imshow(segmented_image)\n",
    "\n",
    "    annot1 = ax1.annotate(\"\", xy=(0,0), xytext=(40,40),textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    annot1.set_visible(False)\n",
    "\n",
    "    annot2 = ax2.annotate(\"\", xy=(0,0), xytext=(40,40),textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    annot2.set_visible(False)\n",
    "\n",
    "    def on_move(event):\n",
    "        if event.inaxes:\n",
    "            x, y  = event.xdata, event.ydata\n",
    "            annot1.xy = [x, y]\n",
    "            x = round(x)\n",
    "            y = round(y)\n",
    "            text = f\"{x}, {y}, {image[y, x]}\"\n",
    "            annot1.set_text(text)\n",
    "            annot1.get_bbox_patch().set_facecolor(cmap(norm(c[0])))\n",
    "            annot1.get_bbox_patch().set_alpha(0.4)\n",
    "            annot1.set_visible(True)\n",
    "\n",
    "            annot2.xy = [x, y]\n",
    "            text = f\"{x}, {y}, {segmented_image[y, x]}\"\n",
    "            annot2.set_text(text)\n",
    "            annot2.get_bbox_patch().set_facecolor(cmap(norm(c[0])))\n",
    "            annot2.get_bbox_patch().set_alpha(0.4)\n",
    "            annot2.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "    fig.canvas.mpl_connect(\"motion_notify_event\", on_move)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#tot_ims = np.array(tot_ims)\n",
    "#fig = px.imshow(tot_ims, binary_string=True, facet_col=0, facet_col_wrap=2)\n",
    "\n",
    "#fig.update_layout(hovermode=\"y unified\")\n",
    "#fig.update_xaxes(showspikes=True, spikecolor=\"green\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=0.1)\n",
    "#fig.update_yaxes(showspikes=True, spikecolor=\"orange\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=0.1)\n",
    "#fig.update_layout(spikedistance=1000, hoverdistance=100)\n",
    "#fig.show()\n",
    "\n",
    "#fig1.update_traces(hovertemplate=None)\n",
    "#fig2.update_traces(hovertemplate=None)\n",
    "#fig1.update_layout(hovermode=\"x\")\n",
    "#fig2.update_layout(hovermode=\"x\")\n",
    "#fig1.show()\n",
    "#fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "#%matplotlib inline\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from felzenszwalb_segmentation_revised import segment\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from  pathlib import Path\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "save_dir= r'E:\\PHD\\Blueberry\\Blueberry\\one_sample_wavelength_change'\n",
    "save_dir = Path(save_dir)\n",
    "\n",
    "save_path = save_dir/'origin1'\n",
    "save_path = save_path / f'*.png'\n",
    "\n",
    "save_path1 = save_dir/'segment1'\n",
    "save_path1 = save_path1 / f'*.png'\n",
    "\n",
    "image_files = glob(save_path.__str__())\n",
    "image_files1 = glob(save_path1.__str__())\n",
    "image_files = sorted(image_files, key=lambda x: float(Path(x).name.split('_')[0]))\n",
    "image_files1 = sorted(image_files1, key=lambda x: float(Path(x).name.split('_')[0]))\n",
    "im_num = len(image_files)\n",
    "im_num1 = len(image_files1)\n",
    "\n",
    "norm = plt.Normalize(1,4)\n",
    "cmap = plt.cm.RdYlGn\n",
    "np.random.seed(10)\n",
    "c = np.random.randint(1,5,size=15)\n",
    "first_time = True\n",
    "# 361 256\n",
    "im_idx = 256\n",
    "def compare_im_with_process(event):\n",
    "    global first_time, im_idx\n",
    "    if True:\n",
    "    #for i_im in range(im_num):\n",
    "    #    if i_im <= 364:\n",
    "    #        continue\n",
    "        if first_time is False:\n",
    "            if event.key == 'a':\n",
    "                im_idx -= 1\n",
    "            if event.key == 'd':\n",
    "                im_idx += 1\n",
    "        i_im = im_idx\n",
    "        image = np.array(Image.open(image_files[i_im]))\n",
    "        segmented_image = np.array(Image.open(image_files1[i_im]))\n",
    "        #segmented_image = segment(image, 0.2, 400, 50)\n",
    "        #segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "        fig = plt.figure(0, figsize=(6, 6))\n",
    "        fig.clear()\n",
    "        ax1 = fig.add_subplot(1, 2, 1)\n",
    "        handle1 = plt.imshow(image)\n",
    "        ax2 = fig.add_subplot(1, 2, 2)\n",
    "        handle2= plt.imshow(segmented_image)\n",
    "        ax1.set_title(wavelengths[i_im])\n",
    "\n",
    "        annot1 = ax1.annotate(\"\", xy=(0,0), xytext=(40,40),textcoords=\"offset points\",\n",
    "                            bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                            arrowprops=dict(arrowstyle=\"->\"))\n",
    "        annot1.set_visible(False)\n",
    "\n",
    "        annot2 = ax2.annotate(\"\", xy=(0,0), xytext=(40,40),textcoords=\"offset points\",\n",
    "                            bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                            arrowprops=dict(arrowstyle=\"->\"))\n",
    "        annot2.set_visible(False)\n",
    "\n",
    "        def on_move(event):\n",
    "            if event.inaxes:\n",
    "                x, y  = event.xdata, event.ydata\n",
    "                annot1.xy = [x, y]\n",
    "                x = round(x)\n",
    "                y = round(y)\n",
    "                text = f\"{x}, {y}, {image[y, x]}\"\n",
    "                annot1.set_text(text)\n",
    "                annot1.get_bbox_patch().set_facecolor(cmap(norm(c[0])))\n",
    "                annot1.get_bbox_patch().set_alpha(0.4)\n",
    "                annot1.set_visible(True)\n",
    "\n",
    "                annot2.xy = [x, y]\n",
    "                text = f\"{x}, {y}, {segmented_image[y, x]}\"\n",
    "                annot2.set_text(text)\n",
    "                annot2.get_bbox_patch().set_facecolor(cmap(norm(c[0])))\n",
    "                annot2.get_bbox_patch().set_alpha(0.4)\n",
    "                annot2.set_visible(True)\n",
    "                fig.canvas.draw_idle()\n",
    "            else:\n",
    "                annot1.set_visible(False)\n",
    "                annot2.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "\n",
    "        fig.canvas.mpl_connect(\"motion_notify_event\", on_move)\n",
    "        if first_time is True:\n",
    "            cid = fig.canvas.mpl_connect('key_press_event', compare_im_with_process)\n",
    "        if first_time is True:\n",
    "            plt.show()\n",
    "            first_time = False\n",
    "        else:\n",
    "            plt.show(block=False)\n",
    "compare_im_with_process(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wavelengths: 897.86"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Repo\\Biang\\Graphics\\Blueberry\\felzenszwalb_segmentation_revised\\utils\\filter_utils.py:14: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  src[y, max(x - i, 0)] + src[y, min(x + i, width - 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from felzenszwalb_segmentation_revised import segment\n",
    "import random\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "title_window = 'HSI corrected'\n",
    "title_window1 = 'processed'\n",
    "font=cv.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "import cv2 as cv\n",
    "import random\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "title_window = 'HSI corrected'\n",
    "title_window1 = 'processed'\n",
    "font=cv.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "from random import randint\n",
    "\n",
    "taget_y_0 = 119\n",
    "taget_y_1 = 290\n",
    "taget_x_0 = 162\n",
    "taget_x_1 = 350\n",
    "\n",
    "def get_random_rgb_image():\n",
    "    rgb = np.zeros(3, dtype=int)\n",
    "    rgb[0] = randint(0, 255)\n",
    "    rgb[1] = randint(0, 255)\n",
    "    rgb[2] = randint(0, 255)\n",
    "    return rgb\n",
    "\n",
    "height = taget_y_1 - taget_y_0\n",
    "width = taget_x_1 - taget_x_0\n",
    "colors = np.zeros(shape=(height * width, 3))\n",
    "for i in range(height * width):\n",
    "    colors[i, :] = get_random_rgb_image()\n",
    "\n",
    "def on_trackbar(idx):\n",
    "    random.seed(10)\n",
    "    np.random.seed(10)\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    im_corrected = im/(ref1-ref)\n",
    "    im_corrected/=im_corrected.max()\n",
    "    print(\"\\r\", f'wavelengths: {wavelengths[idx]}', end=\"\", flush=True)\n",
    "    taget_y_0 = 119\n",
    "    taget_y_1 = 290\n",
    "    taget_x_0 = 162\n",
    "    taget_x_1 = 350\n",
    "    im_corrected = (im_corrected*255).astype(np.uint8)\n",
    "    im_corrected = im_corrected[taget_y_0:taget_y_1, taget_x_0:taget_x_1]\n",
    "    im_corrected = np.concatenate([im_corrected,im_corrected,im_corrected], -1)\n",
    "    #print(im_corrected.shape)\n",
    "    segmented_image = segment(im_corrected, 0.2, 400, 50, colors=colors)\n",
    "    segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "    #cv.putText(im_corrected, str(wavelengths[idx]) , (3, 3), font, 1, 255, 2)\n",
    "    #for i_contour, idx in enumerate(idx_sorted):\n",
    "    #    x, y = center_pts[idx]\n",
    "    #    cv.putText(im_corrected, str(i_contour+1) , (x-100,y-70), font, 1, 255, 2)\n",
    "    cv.imshow(title_window, im_corrected)\n",
    "    cv.imshow(title_window1, segmented_image)\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.namedWindow(title_window1, 0)\n",
    "slider_max = data.shape[2]\n",
    "trackbar_name = f'{wavelengths_bar[0]}:{wavelengths_bar[-1]}'\n",
    "cv.createTrackbar(trackbar_name, title_window, 378, slider_max, on_trackbar)\n",
    "#cv.createTrackbar(trackbar_name, title_window1 , 0, slider_max, on_trackbar)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wavelengths: 1010.64"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from felzenszwalb_segmentation_revised import segment\n",
    "from  pathlib import Path\n",
    "import random\n",
    "\n",
    "from random import randint\n",
    "\n",
    "taget_y_0 = 119\n",
    "taget_y_1 = 290\n",
    "taget_x_0 = 162\n",
    "taget_x_1 = 350\n",
    "\n",
    "def get_random_rgb_image():\n",
    "    rgb = np.zeros(3, dtype=int)\n",
    "    rgb[0] = randint(0, 255)\n",
    "    rgb[1] = randint(0, 255)\n",
    "    rgb[2] = randint(0, 255)\n",
    "    return rgb\n",
    "\n",
    "height = taget_y_1 - taget_y_0\n",
    "width = taget_x_1 - taget_x_0\n",
    "colors = np.zeros(shape=(height * width, 3))\n",
    "for i in numpy save arrayrange(height * width):\n",
    "    colors[i, :] = get_random_rgb_image()\n",
    "\n",
    "wavelengths = data.metadata['wavelength']\n",
    "wavelengths_bar = [round(float(x)) for x in wavelengths]\n",
    "title_window = 'HSI corrected'\n",
    "title_window1 = 'processed'\n",
    "font=cv.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "save_dir= r'E:\\PHD\\Blueberry\\Blueberry\\one_sample_wavelength_change'\n",
    "save_dir = Path(save_dir)\n",
    "wavelength_num = len(wavelengths)\n",
    "\n",
    "cv.namedWindow(title_window, 0)\n",
    "cv.namedWindow(title_window1, 0)\n",
    "\n",
    "for idx in range(wavelength_num):\n",
    "    random.seed(10)\n",
    "    im = data[: , :, idx]\n",
    "    ref = ref_data[: , :, idx]\n",
    "    ref1 = ref1_data[: , :, idx]\n",
    "    im_corrected = im/(ref1-ref)\n",
    "    im_corrected/=im_corrected.max()\n",
    "\n",
    "    print(\"\\r\", f'wavelengths: {wavelengths[idx]}', end=\"\", flush=True)\n",
    "    taget_y_0 = 119\n",
    "    taget_y_1 = 290\n",
    "    taget_x_0 = 162\n",
    "    taget_x_1 = 350\n",
    "    im_corrected = (im_corrected*255).astype(np.uint8)\n",
    "    im_corrected = im_corrected[taget_y_0:taget_y_1, taget_x_0:taget_x_1]\n",
    "    im_corrected = np.concatenate([im_corrected,im_corrected,im_corrected], -1)\n",
    "    segmented_image = segment(im_corrected, 0.2, 400, 50, colors=colors)\n",
    "    segmented_image = segmented_image.astype(np.uint8)\n",
    "\n",
    "    cv.imshow(title_window, im_corrected)\n",
    "    cv.imshow(title_window1, segmented_image)\n",
    "    \n",
    "    save_path = save_dir/'origin'\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = save_path / f'{idx}_{wavelengths[idx]}.png'\n",
    "    #print(save_path)\n",
    "    cv.imwrite(save_path.__str__(), im_corrected)\n",
    "\n",
    "    save_path = save_dir/'segment'\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = save_path / f'{idx}_{wavelengths[idx]}.png'\n",
    "    cv.imwrite(save_path.__str__(), segmented_image)\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check ref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_spectral_data import find_nearest\n",
    "\n",
    "band, idx = find_nearest(wavelengths, 680)\n",
    "print(band, idx)\n",
    "idx = int(idx)\n",
    "#ref = ref_data[200:, :, idx]\n",
    "ref = ref_data[:1600, :, idx]\n",
    "im1 = data[:, :, idx]\n",
    "im1 = im1 / ref\n",
    "\n",
    "band, idx = find_nearest(wavelengths, 900)\n",
    "print(band, idx)\n",
    "idx = int(idx)\n",
    "#ref = ref_data[200:, :, idx]\n",
    "ref = ref_data[:1600, :, idx]\n",
    "im2 = data[:, :, idx]\n",
    "im2 = im2 / ref\n",
    "\n",
    "diff_im = im2-im1\n",
    "diff_im = diff_im[:, :, 0]\n",
    "print(diff_im.min(), diff_im.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_spectral_data import load_hyper_spectral_data, good_dir, bad_dir, good_dir1, bad_dir1\n",
    "from modeling_spectral_data import get_calibrated_image\n",
    "\n",
    "\"\"\"\n",
    "ref_data\n",
    "1st day 1800\n",
    "\n",
    "2nd day 1600\n",
    "    ref_data[:1600, :, 0]\n",
    "\"\"\"\n",
    "\n",
    "hyper_spectral_data_dict, data_idx_dict = load_hyper_spectral_data()\n",
    "ref_data = hyper_spectral_data_dict['ref_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['data_bad', 'data_bad1', 'data_bad2', 'data_bad3', 'data_bad4']\n",
    "#data_names = ['data_good', 'data_good1', 'data_good2', 'data_good3', 'data_good4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name, data_idx_dict):\n",
    "    data = data_idx_dict[data_name]['data']\n",
    "    sample_start_idx = data_idx_dict[data_name]['start_idx']\n",
    "    save_name = data_idx_dict[data_name]['name']\n",
    "\n",
    "    wavelengths = data.metadata['wavelength']\n",
    "    wavelengths = [float(x) for x in wavelengths]\n",
    "    data_num = len(wavelengths)\n",
    "    title_window = 'x'\n",
    "\n",
    "    print(data_name, save_name)\n",
    "    return data, wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_bad bad_1_42\n",
      "679.96 216\n",
      "900.58 380\n",
      "data_bad1 bad_43_84\n",
      "679.96 216\n",
      "900.58 380\n",
      "data_bad2 bad_85_126\n",
      "679.96 216\n",
      "900.58 380\n",
      "data_bad3 bad_127_168\n",
      "679.96 216\n",
      "900.58 380\n",
      "data_bad4 bad_169_210\n",
      "679.96 216\n",
      "900.58 380\n"
     ]
    }
   ],
   "source": [
    "im_corrected_datas = []\n",
    "for data_name in data_names:\n",
    "    data, wavelengths = get_data(data_name, data_idx_dict)\n",
    "    im1 = get_calibrated_image(680, wavelengths, data, ref_data)\n",
    "    im2 = get_calibrated_image(900, wavelengths, data, ref_data)\n",
    "    diff_im = im2-im1\n",
    "    diff_im = diff_im[:, :, 0]\n",
    "    im_corrected_datas.append(diff_im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_0 -0.6053791017294667 1.129282140107775\n",
      "bad_1 -0.6072484012791934 1.1620011186489607\n",
      "bad_2 -0.6119473020875213 1.1504449388209121\n",
      "bad_3 -0.8425890560945177 1.1052668724310515\n",
      "bad_4 -0.7348261794109441 0.95702395081425\n",
      "F:\\test\\xxx.html\n"
     ]
    }
   ],
   "source": [
    "from modeling_spectral_data import show_single_spectral_im_pixel_distribution\n",
    "show_single_spectral_im_pixel_distribution(im_corrected_datas, 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdae7f16d060f2e4f4212789add6457d9369552c195e231f2a645ab38000492f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
